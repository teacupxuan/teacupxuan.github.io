---
title: 关于高性能系统的思考
date: 2025-8-13 22:20:31
tags:
  - 后端架构
categories:
  - 技术分享
description: 总结了高并发系统的演进路径
---

最近我在用Go写服务端的项目，我可以按照prd需求完成功能，同时我的接口也可以被前端正确地使用。但是后期这个接口可能会被10万用户同时请求，我目前接口的很有可能会挂。因为我对数据库进行多表查询和计算，我认为性能不佳。

对于这个事情，我有了一些疑问。现在市面上很多人都同时在用的软件比如tiktok,google,twitter,facebook,这些软件在最开始写代码的时候，接口就能应对几千万乃至上亿的请求吗？如果不能的话，是服务器崩溃后再临时修复代码吗？我发现其实也有很多软件在有很多用户时会崩溃，比如微博会在有明星八卦时崩溃。但微信好像从来没有崩溃过。这又是为什么呢？

带着这些问题，我又和chatgpt进行了探讨，以下是探讨结果。

### 本质
我上述的问题本质上是在问——**高并发系统在从0到大规模用户时，后端接口的性能演进路径。**
实时上，像 TikTok、Google、Twitter 这种公司，并不是一开始就写出能扛上亿并发的系统，它们的架构是**逐步演进**的。


### 1.刚开始的时候，谁都扛不住亿级别流量

绝大部分互联网产品刚上线时：

- 用户量小，接口简单，数据库查询可能直接写在业务里，多表 Join 随便用。
    
- 没有提前准备超大规模架构，因为**过度设计会浪费大量开发成本**（可能产品还没活到用户爆发，就死了）。
    
- 即使是 Google、Facebook，当年的第一个版本也只是一个简单的单体应用 + 数据库。
    

> 典型思路：  
> **先做对 → 再做快 → 最后做大**  
> （先能正确实现功能，再优化性能，最后扩展架构）


### 2.真正的用户量增长，架构会这样演进

当用户数上涨到一定阶段时，会逐步遇到瓶颈：

#### 1. 优化数据库层

- 索引优化（BTree、Hash、GIN、BRIN）
- SQL重写（避免复杂Join，分成多次查询再内存合并）
- 数据缓存（Redis、Memcached）
- 读写分离（主库写，从库读）

#### 2.引入缓存

- 热数据放Redis
- CDN缓存静态资源
- API结果缓存，减少数据库压力

#### 3. 水平扩展（Scale out）

- 应用服务多实例部署（K8s，容器、负载均衡）
- 数据库分库分表

#### 4. 异步化&限流

- 大计算量放消息队列（Kafka、RabbitMQ）异步处理
- 限流 / 降级 （保护数据库不被打爆）

#### 5. 监控 & 弹性扩容

- Prometheus + Grafana 监控性能
- 高峰时自动扩容实例


### 3. “崩溃修复” vs “提前设计”

- **大部分公司是“绣出来的”：** 最开始架构简单，用户暴增后暴露瓶颈，团队才针对性优化。
- **顶尖公司会提前做压测：** 在上线前用压测工具（JMeter、Locust、k6）模拟百万并发，把瓶颈提前暴露出来。
- **两者结合：** 边迭代边压测，发现性能瓶颈时再分布式化。

### 4. 为什么有的软件经常崩溃，有的几乎不崩？

**举例：**

-  微博大V八卦爆发 →  热点流量瞬时暴涨到平时几十倍，架构如果没有限流 / 弹性扩容 → 挂。
-  微信几乎不崩 → 有极强的流量调度和降级策略：
	-  所有数据多机房多活部署
	-  严格的限流 / 灰度发布
	-  每个接口都有缓存兜底（即使数据库挂了，也能用缓存提供有限服务）
	-  大量功能异步化（比如朋友圈的照片并不是实时刷出来的）

### 5. 针对能跑，但性能一般的接口建议

既然接口现在能用，但担心高并发挂掉，可以先做到这几步（不必一步到位到微信那种级别的软件）：

#### 1. 压测接口

-  用k6 / JMeter 模拟 1k、10k、50k并发，看QPS和响应时间。
- 找出瓶颈（数据库、网络、CPU、内存）。

#### 2. 数据库优化

- 加合适的索引（根据 Explain 分析）。
- 拆掉不必要的多表 Join。
- 读多写少的地方用 Redis 缓存。

#### 3. 限流保护

- 在网关层（Nginx / API Gateway）做限流，保护服务不会被瞬时打死。

#### 4. 异步化

- 大计算、批量操作放队列（Kafka/RabbitMQ），异步处理。

#### 5. **监控 & 预警**

- 接口耗时、数据库连接数、错误率都要有监控。


### 6. 后端从单体到高并发的演进路线

```
阶段 0：原型期
 ├── 单体应用（Go / Node / Java）
 ├── 单数据库（MySQL / PostgreSQL）
 ├── 无缓存、无监控
 └── 目标：功能先跑起来（MVP）

       ↓

阶段 1：性能优化期
 ├── 数据库优化
 │    ├── 建立合适的索引
 │    ├── 避免复杂 JOIN
 │    └── 读写分离（主库写，从库读）
 ├── 引入缓存
 │    ├── Redis 缓存热点数据
 │    └── CDN 缓存静态资源
 ├── 基础限流
 │    └── 防止瞬时请求打爆服务
 └── 目标：能稳定服务几万到几十万用户

       ↓

阶段 2：水平扩展期
 ├── 应用水平扩展
 │    ├── 多实例部署（K8s / Docker）
 │    └── 负载均衡（Nginx / API Gateway）
 ├── 数据库扩展
 │    ├── 分库分表
 │    └── 热数据分离
 ├── 异步化处理
 │    └── Kafka / RabbitMQ 处理大计算任务
 └── 目标：支撑百万级并发请求

       ↓

阶段 3：高可用 & 全球化
 ├── 多机房部署（Active-Active）
 ├── 灾备切换（Failover）
 ├── 全链路监控（Prometheus + Grafana）
 ├── 服务降级与熔断
 └── 目标：支撑千万级以上并发，并且高可用（99.99% SLA）

       ↓

阶段 4：超大规模分布式
 ├── 全局分布式缓存（Redis Cluster / Aerospike）
 ├── 数据分片 + 存储中间层（TiDB / Spanner）
 ├── 多活架构 + 流量调度
 ├── 实时弹性扩容（云原生）
 └── 目标：支撑亿级用户，全球低延迟

```


到此为止，了解了一个成熟强大的系统是如何构建出来的了。
